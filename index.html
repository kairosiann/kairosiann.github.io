<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ryan Hwang Kim</title>
    <link rel="stylesheet" href="css/styles.css">
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
</head>
<body>
    <header>
        <h1>Ryan Hwang Kim</h1>
        <nav>
            <ul>
                <li><a href="#education">Education</a></li>
                <li><a href="#work-experiences">Experiences</a></li>
                <!-- <li><a href="#leadership-activities">Activities</a></li> -->
                <li><a href="#projects">Projects</a></li>
                <li><a href="#publications">Publications</a></li>
                <li><a href="#awards">Awards</a></li>
                <!-- <li><a href="#volunteering">Volunteering</a></li>-->
                <li><a href="#blogs">Blog</a></li>
                <!--<li><a href="#news">News</a></li> -->
            </ul>
        </nav>
        <button id="menu-toggle" aria-label="Toggle menu">‚ò∞</button>
    </header>
    <main>
        <aside>
            <img src="assets/profile.jpeg" alt="Profile image" class="profile-image", width=100px, height="auto">
            <h2>Ryan Hwang Kim</h2>
            <p>CS+Math & Global Affairs, YES Scholar @ Yale University</p>
            <ul class="contact-info">
                <li><span class="icon">üåè</span> Seoul üá∞üá∑; Boston üá∫üá∏</li>
                <li><span class="icon">üèõÔ∏è</span> Yale University</li>
                <li><span class="icon">‚úâÔ∏è</span> ryan.h.kim@yale.edu</li>
            </ul>
        </aside>
        <section id="content">

            <div id="about">
                <h2>About</h2>
                Driven, creative, and analytical thinker deeply interested in artificial intelligence and emerging technologies ‚Äì not only the technical, but also the greater societal and business impacts. Always curious about how the world works, hoping to understand it and shape it for the better! <br/>
                Please feel free to reach out at <a href="ryan.h.kim@yale.edu">ryan.h.kim@yale.edu</a>.

                <br/>

                <br/>
                My current primary pre-occupation is serving as a Military Police Officer (31B) with the US Army at USAG Humphreys. My other ongoing engagements are conducted in a part-time basis.


            </div>

            <div id="education">
                <h2>Education</h2>
                <div class="container">
                    <div class="logo">
                        <img src="assets/yale_logo.png" alt="Yale logo", width="50px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">Yale University</div>
                        <div class="degree">B.S. Computer Science + Mathematics, B.A. Global Affairs</div>
                        <div class="date">Fall 2023 ~ Present</div>
                        <div class="location">üìç New Haven, CT</div>
                        <div class="details" style="display: none;">
                            <u>Notable Achievements</u>
                                <li>Yale Engineering & Science (YES) Scholar: Top ~4% of admitted students(< 0.002% of applicants) for demonstrated academic ability.</li>
                        </div>
                    </div>
                </div>

                <div class="container">
                    <div class="logo">
                        <img src="assets/choate_logo.png" alt="Choate logo", width="50px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">Choate Rosemary Hall</div>
                        <div class="degree">High School Diploma</div>
                        <div class="date">Fall 2019 ~ Spring 2023</div>
                        <div class="location">üìç Wallingford, CT</div>
                    </div>
                </div>

            </div>

            <div id="work-experiences">
                <h2>Work Experiences</h2>

                <div class="container">
                    <div class="logo">
                        <!-- <img src="" alt="Stealth logo", width="60px", height="auto"/> -->
                    </div>
                    <div class="text">
                        <div class="school-name">Co-Founder & CEO @ Stealth</div>
                        <div class="date">April 2025 ~ </div>

                        <div class="details" style="display:none">
                            Introducing a new paradigm to the way we interact with information.
                        </div>
                    </div>
                </div>

                <div class="container">
                    <div class="logo">
                        <img src="assets/attentionx_logo.jpeg" alt="AttentionX logo", width="60px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">Board Member @ <a href="https://www.attentionx.github.io">AttentionX</a></div>
                        <div class="date">January 2025 ~ </div>
                        <div class="location">üìç Seoul, South Korea</div>

                        <div class="details" style="display: none">
                            AttentionX, the leading college AI research and startup community in Korea, composed of students from top colleges in Korea and around the world. <br/> <br/>
                            
                            Notable organization accomplishments include successful startups:
                            <li><a href="https://github.com/nari-labs/dia">Nari Labs</a> ‚Äì¬†maker of Dia 1.6B TTS model (#1 on Github and HuggingFace)</li>
                            <li><a href="https://www.linkedin.com/company/weavel/">Weavel</a> ‚Äì¬†Y Combinator S24 batch</li>
                            <li><a href="https://aim-intelligence.com/en">AIM Intelligence</a> ‚Äì¬†2024 Meta Impact Innovation Award Winner, collaborating w/ Anthropic</li><br/>
                            
                            as well as papers published in top conferences:
                            <li><a href="https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/papers/Park_VLAAD_Vision_and_Language_Assistant_for_Autonomous_Driving_WACVW_2024_paper.pdf">"VLAAD: Vision and Language Assistant for Autonomous Driving"</a> ‚Äì¬†WACV 2024 Workshop</li>
                            <li><a href="https://aclanthology.org/2024.findings-emnlp.889.pdf">"Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks"</a> ‚Äì¬†EMNLP 2024</li>
                            <li><a href="https://aclanthology.org/2024.emnlp-industry.41/">"MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline"</a> ‚Äì¬†EMNLP 2024</li>
                            <li><a href="https://neurips.cc/virtual/2023/81194">‚ÄúParameter Efficient Fine-tuning of InstructBLIP for Visual Reasoning‚Äù</a> ‚Äì¬†NeurIPS 2023 Workshop</li>
                        </div>
                    </div>
                </div>

                <div class="container">
                    <div class="logo">
                        <img src="assets/kaist-logo.png" alt="KAIST logo", width="60px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">Part-time Undergraduate Research Intern @ <a href="https://www.clvrai.com">KAIST CLVR Lab</a></div>
                        <div class="date">December 2024 ~ </div>
                        <div class="location">üìç Seoul, South Korea</div>

                        <div class="details" style="display: none">
                            Studying reinforcement learning. Researching robot foundation models and real2sim2real techniques for robots learning. <br/>
                        </div>
                    </div>
                </div>

                <div class="container">
                    <div class="logo">
                        <img src="assets/google-logo.png" alt="Google logo", width="80px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">Global Youth Advisor for Google (via Canvas8)</div>
                        <div class="date">February 2024 ~ </div>
                        <div class="location">üìç Remote</div>

                        <div class="details" style="display: none">
                            Serving as a Global Youth Advisors for Google in collaboration with Canvas8. <br/> <br/>
                            Beta-tested numerous unreleased Google AI software and hardware products, providing in-depth user feedback on output quality, user experience, and social appropriateness of AI-generated responses from a Gen Z perspective. <br/> <br/>
                            Collaborated with Google AI researchers, product managers, UI/UX designers, and marketing teams to ensure seamless alignment of new products/services with the unique needs, preferences, and ethical expectations of Gen Z consumers. <br/> <br/>
                            
                            Provided critical pre-release beta testing and user feedback on products and features including, but not limited to: AI Overviews, AI Mode, Gemini App, Google AI Studio, Google Pixel 9 series, Project Astra, and more.<br/>
                        </div>
                    </div>
                </div>

                <div class="container">
                    <div class="logo">
                        <img src="assets/cais-logo.jpeg" alt="CAIS logo", width="60px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">Research Engineer Intern @ <a href="https://www.safe.ai">Center for AI Safety</a></div>
                        <div class="date">Summer 2024</div>
                        <div class="location">üìç San Francisco, CA</div>

                        <div class="details" style="display: none">
                            Contributed to projects testing various representation engineering and jailbreaking methods against models, evaluating safety benchmarks for capabilities alignment, and creating the largest novel multimodal benchmark to evaluate current and future frontier model's capabilities ‚Äì¬†Humanity's Last Exam (see publications below). <br/> <br/>
                            Co-authored ‚ÄúSafetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress‚Äù, accepted to NeurIPS 2024¬†‚Äì¬†see publications below. <br/>
                        </div>
                    </div>
                </div>

                <div class="container">
                    <div class="logo">
                        <img src="assets/yale-seas-logo.jpeg" alt="Yale SEAS logo", width="50px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">Undergraduate Research Intern @ <a href="https://vision.cs.yale.edu">Yale Vision Lab</a></div>
                        <div class="date">Summer 2023</div>
                        <div class="location">üìç New Haven, CT</div>

                        <div class="details" style="display: none">
                            Developed 3 Generative Adversarial Networks (GANs) using PyTorch and domain adaptation techniques to realistically simulate clear and adverse weather conditions on two autonomous driving datasets to improve autonomous navigation. <br/> <br/>
                            Synthesized and filtered 24GB multimodal dataset on synthetic autonomous driving using depth maps from CARLA.<br/>
                        </div>
                    </div>
                </div>

                <div class="container">
                    <div class="logo">
                        <img src="assets/yale-seas-logo.jpeg" alt="Yale SEAS logo", width="50px", height="auto"/>
                    </div>
                    <div class="text">
                        <div class="school-name">HS Research Intern @ <a href="https://interactive-machines.gitlab.io">Yale Interactive Machines Group</a></div>
                        <div class="date">Summer 2022</div>
                        <div class="location">üìç New Haven, CT</div>

                        <div class="details" style="display: none">
                            Developed survey GUI using ELAN framework and developed deep learning algorithm using PyTorch and C++  to read human facial expressions and evaluate a social robot‚Äôs performance during real-time interactions. <br/> <br/>

                            Developed dynamic stereo camera calibration algorithm for a pair of RGB-D cameras used throughout the lab, leveraging techniques such as inverse kinematics, single value decomposition, and epipolar geometry. <br/> <br/>

                            Work credited in papers <a href="https://dl.acm.org/doi/10.1145/3568162.3576986">‚ÄúSelf-Annotation Methods for Aligning Implicit and Explicit Human Feedback in Human-Robot Interaction‚Äù</a> (ACM/IEEE HRI '23), <a href="https://dl.acm.org/doi/10.1145/3610978.3641090">‚ÄúShutter: A Low-Cost and Flexible Social Robot Platform for In-the-Wild Deployments‚Äù</a> (ACM/IEEE HRI '24).
                        </div>
                        </div>
                    </div>
                </div>
            </div>

            <!--div id="leadership_activities">
                <h2>Leadership Activities</h2>
            </div-->

            <div id="projects">
                <h2>Projects</h2>

                <div class="container project-container">
                    <div class="text">
                        <div class="project-name">Alfred LawBot</div>
                        </div>
                        <div class="details" style="display: none">
                            In collaboration with Yale Law School, developed a generative AI chatbot to parse long, complex legal documents and generate insights, aiding lawyers make decisions more accurately and quickly.

                            Read more about the project <a href="https://news.yale.edu/2024/03/25/ais-legal-revolution">here</a>.
                        </div>
                    </div>
                </div>

                <div class="container project-container">
                    <div class="text">
                        <div class="project-name">Autonomous COVID-19 Robot</div>
                        </div>
                        <div class="details" style="display: none">
                            Throughout the COVID-19 pandemic, the most common symptom displayed by patients has been a fever, leading to the use of temperature scanning as a preemptive measure to detect potential carriers of the virus. Human employees with handheld thermometers have been used to fulfill this task, however this puts them at risk as they cannot be physically distanced and the sequential nature of this method leads to great inconveniences and inefficiency. The proposed solution is an autonomously navigating robot capable of conversing and scanning people's temperature to detect fevers and help screen for COVID-19. To satisfy this objective, the robot must be able to (1) navigate autonomously, (2) detect and track people, and (3) get individuals' temperature reading and converse with them if it exceeds 38¬∞C. An autonomously navigating mobile robot is used with a manipulator controlled using a face tracking algorithm, and an end effector consisting of a thermal camera, smartphone, and chatbot. The goal of this project is to develop a functioning solution that performs the above tasks. In addition, technical challenges encountered, and their engineering solutions will be presented, and recommendations will be made for enhancements that could be incorporated when approaching commercialization.<br/>
                        </div>
                    </div>
                </div>
            </div>

            <div id="publications">
                <h2>Publications</h2>
                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">Humanity's Last Exam</div>
                        <div class="location">Long Phan, Alice Gatti, Ziwei Han, ...  <b>Ryan H. Kim</b>, ... et al.</div>
                        <div class="publication-links">
                            <a href="https://agi.safe.ai/" target="_blank">[Website]</a>
                            <a href="https://arxiv.org/abs/2501.14249" target="_blank">[Paper]</a>
                            <a href="https://huggingface.co/datasets/cais/hle" target="_blank">[Dataset]</a>
                            <a href="https://github.com/centerforaisafety/hle" target="_blank">[Code]</a>
                        </div>
                        <div class="details" style="display: none">
                            <u>Abstract</u> <br/>
                            Benchmarks are important tools for tracking the rapid advancements in large language model (LLM) capabilities. However, benchmarks are not keeping pace in difficulty: LLMs now achieve over 90% accuracy on popular benchmarks like MMLU, limiting informed measurement of state-of-the-art LLM capabilities. In response, we introduce Humanity's Last Exam (HLE), a multi-modal benchmark at the frontier of human knowledge, designed to be the final closed-ended academic benchmark of its kind with broad subject coverage. HLE consists of 2,500 questions across dozens of subjects, including mathematics, humanities, and the natural sciences. HLE is developed globally by subject-matter experts and consists of multiple-choice and short-answer questions suitable for automated grading. Each question has a known solution that is unambiguous and easily verifiable, but cannot be quickly answered via internet retrieval. State-of-the-art LLMs demonstrate low accuracy and calibration on HLE, highlighting a significant gap between current LLM capabilities and the expert human frontier on closed-ended academic questions. To inform research and policymaking upon a clear understanding of model capabilities, we publicly release HLE at this https URL.
                        </div>
                    </div>
                </div>

                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?</div>
                        <div class="location">NeurIPS 2024 | Richard Ren, Steven Basart, ...  <b>Ryan H. Kim</b>, ... Dan Hendrycks et al.</div>
                        <div class="publication-links">
                            <a href="https://www.safetywashing.ai/" target="_blank">[Website]</a>
                            <a href="publications/safetywashing.pdf" target="_blank">[Paper]</a>
                            <a href="https://github.com/centerforaisafety/safetywashing" target="_blank">[Code]</a>
                        </div>
                        <div class="details" style="display: none">
                            <u>Abstract</u> <br/>
                            As artificial intelligence systems grow more powerful, there has been increasing interest in "AI safety" research to address emerging and future risks. However, the field of AI safety remains poorly defined and inconsistently measured, leading to confusion about how researchers can contribute. This lack of clarity is compounded by the unclear relationship between AI safety benchmarks and upstream general capabilities (e.g., general knowledge and reasoning). To address these issues, we conduct a comprehensive meta-analysis of AI safety benchmarks, empirically analyzing their correlation with general capabilities across dozens of models and providing a survey of existing directions in AI safety. Our findings reveal that many safety benchmarks highly correlate with both upstream model capabilities and training compute, potentially enabling "safetywashing" ‚Äî where capability improvements are misrepresented as safety advancements. Based on these findings, we propose an empirical foundation for developing more meaningful safety metrics and define AI safety in a machine learning research context as a set of clearly delineated research goals that are empirically separable from generic capabilities advancements. In doing so, we aim to provide a more rigorous framework for AI safety research, advancing the science of safety evaluations and clarifying the path towards measurable progress.
                        </div>
                    </div>
                </div>

                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">JARVITS: A Novel Deep Learning IoT Traffic Control System for Real-time Detection and Signal Optimization</div>
                        <div class="location">IEEE MIT URTC 2022 | <b>Ryan H. Kim </b>.</div>
                        <div class="publication-links">
                            <a href="https://ieeexplore.ieee.org/document/10002229" target="_blank">[Paper]</a>
                            <a href="https://github.com/kairosiann/jarvits" target="_blank">[Code]</a>
                        </div>
                        <div class="details" style="display: none">
                            <u>Abstract</u> <br/>
                            As artificial intelligence systems grow more powerful, there has been increasing interest in "AI safety" research to address emerging and future risks. However, the field of AI safety remains poorly defined and inconsistently measured, leading to confusion about how researchers can contribute. This lack of clarity is compounded by the unclear relationship between AI safety benchmarks and upstream general capabilities (e.g., general knowledge and reasoning). To address these issues, we conduct a comprehensive meta-analysis of AI safety benchmarks, empirically analyzing their correlation with general capabilities across dozens of models and providing a survey of existing directions in AI safety. Our findings reveal that many safety benchmarks highly correlate with both upstream model capabilities and training compute, potentially enabling "safetywashing" ‚Äî where capability improvements are misrepresented as safety advancements. Based on these findings, we propose an empirical foundation for developing more meaningful safety metrics and define AI safety in a machine learning research context as a set of clearly delineated research goals that are empirically separable from generic capabilities advancements. In doing so, we aim to provide a more rigorous framework for AI safety research, advancing the science of safety evaluations and clarifying the path towards measurable progress.
                        </div>
                    </div>
                </div>

                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">Development of a conversing, temperature scanning, autonomously navigating robot to help screen for COVID-19</div>
                        <div class="location">IEEE ICCAS 2021 | <b>Ryan H. Kim</b>, Hyung Gi Min.</div>
                        <div class="publication-links">
                            <a href="https://ieeexplore.ieee.org/document/9648849" target="_blank">[Paper]</a>
                            <a href="https://github.com/kairosiann/covid19_robot_project" target="_blank">[Code]</a>
                        </div>
                        <div class="details" style="display: none">
                            <u>Abstract</u> <br/>
                            As artificial intelligence systems grow more powerful, there has been increasing interest in "AI safety" research to address emerging and future risks. However, the field of AI safety remains poorly defined and inconsistently measured, leading to confusion about how researchers can contribute. This lack of clarity is compounded by the unclear relationship between AI safety benchmarks and upstream general capabilities (e.g., general knowledge and reasoning). To address these issues, we conduct a comprehensive meta-analysis of AI safety benchmarks, empirically analyzing their correlation with general capabilities across dozens of models and providing a survey of existing directions in AI safety. Our findings reveal that many safety benchmarks highly correlate with both upstream model capabilities and training compute, potentially enabling "safetywashing" ‚Äî where capability improvements are misrepresented as safety advancements. Based on these findings, we propose an empirical foundation for developing more meaningful safety metrics and define AI safety in a machine learning research context as a set of clearly delineated research goals that are empirically separable from generic capabilities advancements. In doing so, we aim to provide a more rigorous framework for AI safety research, advancing the science of safety evaluations and clarifying the path towards measurable progress.
                        </div>
                    </div>
                </div>
                
            </div>

            <div id="awards">
                <h2>Awards</h2>
                <!-- <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">Korea Presidential Science Scholarship</div>
                        <div class="location">$200k scholarship; Most prestigious undergraduate scholarship in South Korea, awarded for academic excellence in STEM. </div>
                    </div>
                </div> -->

                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">Yale Engineering & Science (YES) Scholar</div>
                        <div class="location">Awarded to top ~4% of admitted students (&lt 0.002% of applicants) for demonstrated academic ability.</div>
                    </div>
                </div>

                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">Regeneron (ex-Westinghouse, Intel) Science Talent Search (STS) Scholar</div>
                        <div class="location">$2k prize; Top 300 semifinalist (scholar) in the #1 high school STEM research competition in the United States.</div>
                    </div>
                </div>

                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">Silver Award, Samsung HumanTech Paper Award (ÏÇºÏÑ± Ìú¥Î®ºÌÖåÌÅ¨ ÎÖºÎ¨∏ÎåÄÏÉÅ ‚Äì ÏùÄÏÉÅ)</div>
                        <div class="location">$5k prize; 2nd Place in the Mathematics/Data Processing category in the #1 high school STEM research competition in South Korea.</div>
                    </div>
                </div>

                <div class="container publications-container">
                    <div class="text">
                        <div class="paper-name">AIME x4</div>
                        <div class="location">4-time American Invitational Mathematics Exam participant</div>
                    </div>
                </div>
            </div>

            <div id="blogs">
                <h2>Blogs</h2>
                <div class="container blog-container">
                    <div class="text">
                        <a href="blog-link" target="_blank">
                            <div class="blog-name">Hello world!</div></a>
                        <div class="date">Coming soon...</div>
                    </div>
                </div>
            </div>

            <div id="Fun">
                <h2>Hobbies</h2>
                <p>
                    Reading ‚Äì¬†Check out what's currently on my mind <a href="https://www.goodreads.com/user/show/90382592-ryan" target="_blank">here</a>. <br/>
                    Sports ‚Äì¬†Golf, Squash, Ski, Soccer. <br/>
                    Music ‚Äì¬†In a previous life, I used to be a cellist and performed at the Kennedy Center in Washington DC.
                </p>
            </div>

        </section>
    </main>
    <script src="js/script.js"></script>
</body>
</html>